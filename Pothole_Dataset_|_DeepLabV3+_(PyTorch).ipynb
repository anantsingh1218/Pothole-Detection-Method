{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 866953,
          "sourceType": "datasetVersion",
          "datasetId": 430832
        }
      ],
      "dockerImageVersionId": 30761,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Pothole Dataset | DeepLabV3+ (PyTorch) ",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anantsingh1218/Pothole-Detection-Method/blob/main/Pothole_Dataset_%7C_DeepLabV3%2B_(PyTorch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "atulyakumar98_pothole_detection_dataset_path = kagglehub.dataset_download('atulyakumar98/pothole-detection-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtLTp-QV_uk7",
        "outputId": "80e985d7-7638-4ab1-b7ce-4f66d4051249"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 align=\"center\" style=\"color: rgb(51, 204, 255); font-weight: bold; font-size: 38px\">\n",
        "<br>\n",
        "  PyTorch Deeplabv3+ with the Pothole Datase â’¶\n",
        "</h3>\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T11:23:31.782589Z",
          "iopub.execute_input": "2024-08-28T11:23:31.783352Z",
          "iopub.status.idle": "2024-08-28T11:23:31.789133Z",
          "shell.execute_reply.started": "2024-08-28T11:23:31.78331Z",
          "shell.execute_reply": "2024-08-28T11:23:31.788055Z"
        },
        "id": "rDD2KQZF_uk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![d5ed2274-3d5e-4723-8bcb-3dd92160161f.jpg](attachment:0dc25c13-3b47-461c-a041-cac73223a95d.jpg)"
      ],
      "metadata": {
        "id": "bc_wUnpI_uk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Download Dataset"
      ],
      "metadata": {
        "id": "emiRhzLg_uk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"IYh8x1BH6s4Eomk0LEJC\")\n",
        "project = rf.workspace(\"potholesdetection-aq76f\").project(\"potholes-detection-ohg1g\")\n",
        "version = project.version(3)\n",
        "dataset = version.download(\"coco-segmentation\")\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-21T07:32:20.026524Z",
          "iopub.execute_input": "2024-10-21T07:32:20.027507Z",
          "iopub.status.idle": "2024-10-21T07:34:50.808799Z",
          "shell.execute_reply.started": "2024-10-21T07:32:20.027451Z",
          "shell.execute_reply": "2024-10-21T07:34:50.807009Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrL38Zjc_uk-",
        "outputId": "8396e246-d9fd-4b1f-f392-ddc8fae9b71e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.49)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (10.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.6)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.54.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u24xX6KS_uk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Import Libraries"
      ],
      "metadata": {
        "id": "0klrZwKM_uk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation_models_pytorch --quiet\n",
        "!pip install pycocotools --quiet"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T11:09:21.914253Z",
          "iopub.execute_input": "2024-08-28T11:09:21.91453Z",
          "iopub.status.idle": "2024-08-28T11:09:55.852749Z",
          "shell.execute_reply.started": "2024-08-28T11:09:21.914499Z",
          "shell.execute_reply": "2024-08-28T11:09:55.851533Z"
        },
        "trusted": true,
        "id": "xB-_AxMg_uk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BMNm4idR_uk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.init as initer\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "from pycocotools.coco import COCO\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T11:09:55.854629Z",
          "iopub.execute_input": "2024-08-28T11:09:55.854982Z",
          "iopub.status.idle": "2024-08-28T11:10:00.188193Z",
          "shell.execute_reply.started": "2024-08-28T11:09:55.854936Z",
          "shell.execute_reply": "2024-08-28T11:10:00.18744Z"
        },
        "trusted": true,
        "id": "Ns9RaTvu_uk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Potholes Dataset"
      ],
      "metadata": {
        "id": "XOZJF5a-_ulA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1) Custom Dataset"
      ],
      "metadata": {
        "id": "YsgXoigz_ulA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PotholeDataset(Dataset):\n",
        "    def __init__(self, root=\"/content/Potholes-Detection-3\", image_set=\"train\", transform=None):\n",
        "        # Set image folder based on the dataset type (train/valid/test)\n",
        "        root = os.path.join(root, image_set)\n",
        "\n",
        "        # Initialize COCO API and get image/annotation info\n",
        "        self.coco = COCO(os.path.join(root, \"_annotations.coco.json\"))\n",
        "        cat_ids = self.coco.getCatIds(catNms=[\"potholes\"])[1]\n",
        "        self.img_ids = self.coco.getImgIds(catIds=cat_ids)\n",
        "\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "\n",
        "    def _getImgInfo(self, idx):\n",
        "        # Retrieve image info (name, height, width)\n",
        "        img_info = self.coco.loadImgs(ids=idx)[0]\n",
        "        return img_info[\"file_name\"], img_info['height'], img_info['width']\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return dataset size\n",
        "        return len(self.img_ids)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        # Load image and mask\n",
        "        img_idx = self.img_ids[item]\n",
        "        img_name, height, width = self._getImgInfo(img_idx)\n",
        "        img = cv2.cvtColor(cv2.imread(os.path.join(self.root, img_name)), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Create mask from annotations\n",
        "        anns = self.coco.loadAnns(self.coco.getAnnIds(imgIds=img_idx))\n",
        "        mask = sum(self.coco.annToMask(ann) for ann in anns)\n",
        "\n",
        "        # Apply transformations if provided\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=img, mask=mask)\n",
        "            img, mask = augmented['image'], augmented['mask']\n",
        "\n",
        "        return img, mask\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-21T07:48:59.563014Z",
          "iopub.execute_input": "2024-10-21T07:48:59.564113Z",
          "iopub.status.idle": "2024-10-21T07:48:59.620161Z",
          "shell.execute_reply.started": "2024-10-21T07:48:59.564025Z",
          "shell.execute_reply": "2024-10-21T07:48:59.618396Z"
        },
        "trusted": true,
        "id": "jfetwQUT_ulA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2 Visualize Image"
      ],
      "metadata": {
        "id": "Lt8LAaEc_ulA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function for data visualization\n",
        "def visualize(**images):\n",
        "    \"\"\"PLot images in one row.\"\"\"\n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(20,10))\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1,n, i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T11:10:00.202707Z",
          "iopub.execute_input": "2024-08-28T11:10:00.202988Z",
          "iopub.status.idle": "2024-08-28T11:10:00.21487Z",
          "shell.execute_reply.started": "2024-08-28T11:10:00.202958Z",
          "shell.execute_reply": "2024-08-28T11:10:00.214108Z"
        },
        "trusted": true,
        "id": "DetAKket_ulA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainsform = A.Compose([\n",
        "    A.Resize(224,224),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "pothole_Dataset = PotholeDataset(image_set= \"train\", transform = trainsform)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T11:10:00.216153Z",
          "iopub.execute_input": "2024-08-28T11:10:00.216453Z",
          "iopub.status.idle": "2024-08-28T11:10:00.262036Z",
          "shell.execute_reply.started": "2024-08-28T11:10:00.216413Z",
          "shell.execute_reply": "2024-08-28T11:10:00.261239Z"
        },
        "trusted": true,
        "id": "unWJjENb_ulA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx1, idx2 = np.random.randint(1,800), np.random.randint(1,800)\n",
        "img, mask = pothole_Dataset[idx1]\n",
        "img2, mask2 = pothole_Dataset[idx2]\n",
        "print(\"Img:\", img.shape)\n",
        "print(\"Mask:\", mask.shape)\n",
        "print(\"Max Value Img:\",img.max())\n",
        "print(\"Max Value Mask: {} | Unique Value Mask: {}\".format(mask.max(), mask.unique()))\n",
        "\n",
        "visualize(\n",
        "    image1=img.permute(1,2,0),\n",
        "    mask1=mask.squeeze(),\n",
        "    image2 = img2.permute(1,2,0),\n",
        "    mask2 = mask2.squeeze(),\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T11:10:00.263072Z",
          "iopub.execute_input": "2024-08-28T11:10:00.263355Z",
          "iopub.status.idle": "2024-08-28T11:10:00.857398Z",
          "shell.execute_reply.started": "2024-08-28T11:10:00.263324Z",
          "shell.execute_reply": "2024-08-28T11:10:00.856522Z"
        },
        "trusted": true,
        "id": "9s-ncGxM_ulB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Metrics"
      ],
      "metadata": {
        "id": "4GBa3SlK_ulB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def intersectionAndUnionGPU(output, target, K, ignore_index=255):\n",
        "    # 'K' classes, output and target sizes are N or N * L or N * H * W, each value in range 0 to K - 1.\n",
        "    assert (output.dim() in [1, 2, 3])\n",
        "    assert output.shape == target.shape\n",
        "    output = output.view(-1)\n",
        "    target = target.view(-1)\n",
        "    output[target == ignore_index] = ignore_index\n",
        "    intersection = output[output == target]\n",
        "    area_intersection = torch.histc(intersection, bins=K, min=0, max=K-1)\n",
        "    area_output = torch.histc(output, bins=K, min=0, max=K-1)\n",
        "    area_target = torch.histc(target, bins=K, min=0, max=K-1)\n",
        "    area_union = area_output + area_target - area_intersection\n",
        "    return area_intersection, area_union, area_target\n",
        "\n",
        "def check_mkdir(dir_name):\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.mkdir(dir_name)\n",
        "\n",
        "def step_learning_rate(base_lr, epoch, step_epoch, multiplier=0.1):\n",
        "    \"\"\"Sets the learning rate to the base LR decayed by 10 every step epochs\"\"\"\n",
        "    lr = base_lr * (multiplier ** (epoch // step_epoch))\n",
        "    return lr"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T11:10:00.859025Z",
          "iopub.execute_input": "2024-08-28T11:10:00.859388Z",
          "iopub.status.idle": "2024-08-28T11:10:00.869894Z",
          "shell.execute_reply.started": "2024-08-28T11:10:00.859353Z",
          "shell.execute_reply": "2024-08-28T11:10:00.868967Z"
        },
        "trusted": true,
        "id": "Wgus_sjO_ulB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Traning Model"
      ],
      "metadata": {
        "id": "l-edS5Zo_ulB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1) Define Transform"
      ],
      "metadata": {
        "id": "OWM2JQ1q_ulB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transform_size = 257\n",
        "#Define trainform to images\n",
        "def img_transform(trainsize= 256):\n",
        "    train_transform = A.Compose([\n",
        "    A.Rotate([-10,10]),\n",
        "    A.RandomScale([0.5,2]),\n",
        "    A.GaussianBlur(),\n",
        "    A.HorizontalFlip(),\n",
        "    A.Resize(width=trainsize, height=trainsize),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
        "    ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "    test_transform = A.Compose([\n",
        "        A.Resize(width=trainsize, height=trainsize),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "    return train_transform, test_transform"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T11:10:00.871021Z",
          "iopub.execute_input": "2024-08-28T11:10:00.871299Z",
          "iopub.status.idle": "2024-08-28T11:10:00.879652Z",
          "shell.execute_reply.started": "2024-08-28T11:10:00.871268Z",
          "shell.execute_reply": "2024-08-28T11:10:00.878657Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "Wdv-fgbT_ulB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2) EarlyStopping"
      ],
      "metadata": {
        "id": "-FdKib-G_ulB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "#patience, min_delta, restore_best_weights, best_model, best_loss counter status\n",
        "#copy.deepcopy\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, min_delta=0, restore_best_weights=False):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.best_model = None\n",
        "        self.best_loss = None\n",
        "        self.counter = 0\n",
        "        self.status = \"\"\n",
        "\n",
        "    def __call__(self, model, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_model = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        elif self.best_loss - val_loss > self.min_delta:\n",
        "            self.best_model = copy.deepcopy(model.state_dict())\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.status = f\"Stop on {self.counter}\"\n",
        "                if self.restore_best_weights:\n",
        "                    model.load_state_dict(self.best_model)\n",
        "                return True\n",
        "        self.status = f\"{self.counter}/{self.patience}\"\n",
        "        return False"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T11:10:00.880875Z",
          "iopub.execute_input": "2024-08-28T11:10:00.8812Z",
          "iopub.status.idle": "2024-08-28T11:10:00.892294Z",
          "shell.execute_reply.started": "2024-08-28T11:10:00.881168Z",
          "shell.execute_reply": "2024-08-28T11:10:00.891529Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "AVj0vFM-_ulB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.3) Traning fuction and Eval Fuction"
      ],
      "metadata": {
        "id": "qO2jRu2a_ulC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training fuction\n",
        "def train(model,train_dataloader,device,optimizer, epoch, EPOCHS, writer, train_loss_meter, criterion):\n",
        "    model.train()\n",
        "    train_progress= tqdm(train_dataloader, colour=\"cyan\")\n",
        "\n",
        "    for idx, img_mask in enumerate(train_progress):\n",
        "        img = img_mask[0].float().to(device) #img - B,C,H,W\n",
        "        mask = img_mask[1].long().to(device) #label - B,H,W\n",
        "        y_pred = model(img) #B,1, H, W\n",
        "        y_pred = y_pred.squeeze() #B H W\n",
        "\n",
        "        #Optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = criterion(y_pred, mask)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_meter.update(loss.item())\n",
        "\n",
        "        # tracking the loss function\n",
        "        writer.add_scalar(\"Train/Loss\", train_loss_meter.avg, epoch*len(train_dataloader)+idx)\n",
        "\n",
        "        train_progress.set_description(\"TRAIN| Epoch: {}/{}| Iter: {}/{} | Loss: {:0.4f} | lr: {}\".format(\n",
        "            epoch+1, EPOCHS, idx+1, len(train_dataloader), loss, optimizer.param_groups[0]['lr']))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T11:10:00.895183Z",
          "iopub.execute_input": "2024-08-28T11:10:00.895455Z",
          "iopub.status.idle": "2024-08-28T11:10:00.903789Z",
          "shell.execute_reply.started": "2024-08-28T11:10:00.895425Z",
          "shell.execute_reply": "2024-08-28T11:10:00.902884Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "Blccn5c4_ulC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate function\n",
        "def evaluate(model,val_dataloader,device, num_classes, intersection_meter, union_meter, target_meter):\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx, img_mask in enumerate(val_dataloader):\n",
        "            img = img_mask[0].float().to(device)\n",
        "            mask = img_mask[1].long().to(device) #B W H\n",
        "\n",
        "            y_pred = model(img) #B, 1, H, W\n",
        "            y_pred = y_pred.squeeze() #B H W\n",
        "\n",
        "            y_pred[y_pred>0]=1 #BWH\n",
        "            y_pred[y_pred<0]=0 #BWH\n",
        "\n",
        "            intersection, union, target = intersectionAndUnionGPU(y_pred.float(), mask.float(), num_classes)\n",
        "            intersection, union, target = intersection.cpu().numpy(), union.cpu().numpy(), target.cpu().numpy()\n",
        "            intersection_meter.update(intersection), union_meter.update(union), target_meter.update(target)\n",
        "\n",
        "            if idx>40: break\n",
        "\n",
        "        #compute acc, iou, dice\n",
        "        accuracy_class = intersection_meter.sum / (target_meter.sum + 1e-10)\n",
        "        iou_class = intersection_meter.sum / (union_meter.sum + 1e-10)\n",
        "        dice_class = (2 * intersection_meter.sum) / (intersection_meter.sum + union_meter.sum + 1e-10) #vector 21D\n",
        "        macc = np.mean(accuracy_class)\n",
        "        miou = np.mean(iou_class) #mean vector 21D\n",
        "        mdice = np.mean(dice_class) #mean vector 21D\n",
        "\n",
        "    return macc, miou, mdice"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T11:10:00.905063Z",
          "iopub.execute_input": "2024-08-28T11:10:00.905716Z",
          "iopub.status.idle": "2024-08-28T11:10:00.916048Z",
          "shell.execute_reply.started": "2024-08-28T11:10:00.905651Z",
          "shell.execute_reply": "2024-08-28T11:10:00.915178Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "W6Zdgyqh_ulC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.4) Traning Deeplabv3 ++ Model"
      ],
      "metadata": {
        "id": "AgEEsWJT_ulC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.optim as optim\n",
        "\n",
        "from collections import OrderedDict\n",
        "import segmentation_models_pytorch as smp\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "def main(learning_rate, batch_size, epochs, num_workers, data_path, model_save_path, tensorboard_path, num_classes, checkpoint_path):\n",
        "\n",
        "    # Create model save directory if it doesn't exist\n",
        "    if not os.path.isdir(model_save_path):\n",
        "        os.mkdir(model_save_path)\n",
        "    # Creater tensorboard directory\n",
        "    if os.path.isdir(tensorboard_path):\n",
        "        shutil.rmtree(tensorboard_path)\n",
        "    os.mkdir(tensorboard_path)\n",
        "\n",
        "\n",
        "    # Data augmentation and preprocessing for training and testing\n",
        "    train_transform, test_transform = img_transform()\n",
        "\n",
        "    # Create datasets and dataloaders\n",
        "    train_dataset = PotholeDataset(image_set=\"train\", transform=train_transform)\n",
        "    test_dataset = PotholeDataset(image_set=\"valid\", transform=test_transform)\n",
        "\n",
        "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, drop_last=True)\n",
        "    val_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, drop_last=True)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load model and move it to the appropriate device\n",
        "    model = smp.DeepLabV3Plus(encoder_name=\"resnext101_32x8d\",encoder_weights=\"imagenet\",in_channels=3,classes= num_classes).to(device)\n",
        "\n",
        "    # Initialize optimizer and loss function\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = smp.losses.SoftBCEWithLogitsLoss(ignore_index=-100, reduction='mean', smooth_factor=0.05)\n",
        "\n",
        "    # Best validation IoU for saving the best model\n",
        "    best_predict = -1\n",
        "    current_epoch = 0\n",
        "\n",
        "\n",
        "    # Metrics\n",
        "    train_loss_meter = AverageMeter()\n",
        "    intersection_meter = AverageMeter()\n",
        "    union_meter = AverageMeter()\n",
        "    target_meter = AverageMeter()\n",
        "\n",
        "    # Early Stop\n",
        "    es = EarlyStopping(patience=14,restore_best_weights=False)\n",
        "\n",
        "    # set up learning rate scheduler\n",
        "    scheduler= optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4, threshold= 1e-4, min_lr=0)\n",
        "\n",
        "    # difine Tensorboard\n",
        "    writer = SummaryWriter(tensorboard_path)\n",
        "\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(current_epoch,epochs): #EPOCHS\n",
        "        train_loss_meter.reset()\n",
        "        intersection_meter.reset()\n",
        "        union_meter.reset()\n",
        "        target_meter.reset()\n",
        "\n",
        "        train(model,train_dataloader,device,optimizer, epoch, epochs, writer, train_loss_meter,criterion)\n",
        "        acc, miou, dice = evaluate(model,val_dataloader,device, num_classes, intersection_meter, union_meter, target_meter)\n",
        "\n",
        "        # write in tensorboard\n",
        "        writer.add_scalar(\"Test/Acc\", acc, epoch)\n",
        "        writer.add_scalar(\"Test/mIOU\", miou, epoch)\n",
        "        writer.add_scalar(\"Test/Dice\", dice, epoch)\n",
        "\n",
        "        # update learning rate\n",
        "        scheduler.step(1-miou)\n",
        "\n",
        "        #Create checkpoint\n",
        "        checkpoint = {\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"epoch\": epoch,\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"dice\": dice\n",
        "        }\n",
        "\n",
        "        # Save last checkpoint\n",
        "        torch.save(checkpoint, os.path.join(model_save_path, \"last.h5\"))\n",
        "\n",
        "        # Save best checkpoint based on dice score\n",
        "        if dice > best_predict:\n",
        "            torch.save(checkpoint, os.path.join(model_save_path, \"best.h5\"))\n",
        "            best_predict = dice\n",
        "\n",
        "        if es(model, 1-miou):\n",
        "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
        "            break\n",
        "\n",
        "        print(\"VAL| Acc:{:0.4f}  | mIOU: {:0.4f} | Dice: {:0.4f} | EStop: {}\".format(\n",
        "             acc, miou, dice, es.status))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T11:10:00.917346Z",
          "iopub.execute_input": "2024-08-28T11:10:00.917802Z",
          "iopub.status.idle": "2024-08-28T11:10:16.396449Z",
          "shell.execute_reply.started": "2024-08-28T11:10:00.91776Z",
          "shell.execute_reply": "2024-08-28T11:10:16.395719Z"
        },
        "trusted": true,
        "id": "-OAWer_X_ulC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Hyperparameters and paths\n",
        "    learning_rate = 1e-4\n",
        "    batch_size = 24\n",
        "    epochs = 50\n",
        "    num_workers = os.cpu_count()\n",
        "    data_path = \"data\"\n",
        "    model_save_path = \"/content/Potholes-Detection-3trained_model\"\n",
        "    tensorboard_path = \"/content/Potholes-Detection-3/tensorboard\"\n",
        "    num_classes = 1\n",
        "\n",
        "    main(learning_rate,batch_size,epochs,num_workers,data_path,model_save_path,\n",
        "        tensorboard_path,num_classes,model_save_path)\n",
        "    pass"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T11:10:25.42815Z",
          "iopub.execute_input": "2024-08-28T11:10:25.429142Z",
          "iopub.status.idle": "2024-08-28T11:14:49.574572Z",
          "shell.execute_reply.started": "2024-08-28T11:10:25.42909Z",
          "shell.execute_reply": "2024-08-28T11:14:49.573146Z"
        },
        "trusted": true,
        "id": "niwOzNdC_ulC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) Inference"
      ],
      "metadata": {
        "id": "_nYyRwmd_ulD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1) Create UnNormalize Fuction"
      ],
      "metadata": {
        "id": "UnhFeXxG_ulD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UnNormalize(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
        "        Returns:\n",
        "            Tensor: Normalized image.\n",
        "        \"\"\"\n",
        "        for t, m, s in zip(tensor, self.mean, self.std):\n",
        "            t.mul_(s).add_(m)\n",
        "            # The normalize code -> t.sub\n",
        "        return tensor\n",
        "\n",
        "unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T11:15:09.629146Z",
          "iopub.execute_input": "2024-08-28T11:15:09.629539Z",
          "iopub.status.idle": "2024-08-28T11:15:09.63602Z",
          "shell.execute_reply.started": "2024-08-28T11:15:09.629501Z",
          "shell.execute_reply": "2024-08-28T11:15:09.635106Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "B_DR87FC_ulD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2) Create Prediction Show Images"
      ],
      "metadata": {
        "id": "j_0A4V5k_ulD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_show_image_grid(model_pth, device, test_transform, num_classes, num_imgs):\n",
        "    # Load model checkpoint\n",
        "    checkpoint = torch.load(model_pth)\n",
        "    model = smp.DeepLabV3Plus(encoder_name=\"resnext101_32x8d\",encoder_weights=\"imagenet\",in_channels=3,classes= num_classes)\n",
        "\n",
        "    # Load the updated state_dict into the model\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Load validation dataset\n",
        "    image_dataset = PotholeDataset(image_set=\"test\", transform=test_transform)\n",
        "\n",
        "\n",
        "    images, orig_masks, pred_masks = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for i in range(num_imgs) :\n",
        "            idx = np.random.randint(len(image_dataset))\n",
        "            ori_img, mask = image_dataset[idx]\n",
        "            img = ori_img\n",
        "            img = img.to(device).float().unsqueeze(0)\n",
        "            y_pred = model(img)\n",
        "\n",
        "            y_pred = y_pred.squeeze() #B H W\n",
        "            y_pred[y_pred>0]=1 #BWH\n",
        "            y_pred[y_pred<0]=0 #BWH\n",
        "            y_pred = y_pred.long()\n",
        "\n",
        "            orig_masks.append(mask.cpu())\n",
        "            pred_masks.append(y_pred.cpu())\n",
        "            images.append(unorm(ori_img).permute(1, 2, 0))\n",
        "\n",
        "    # Combine images and masks for display\n",
        "    images.extend(orig_masks)\n",
        "    images.extend(pred_masks)\n",
        "\n",
        "    # Plot images and masks\n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "    for i in range(1, 3*num_imgs + 1):\n",
        "        fig.add_subplot(3, num_imgs, i)\n",
        "        plt.imshow(images[i - 1])\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T11:16:42.277659Z",
          "iopub.execute_input": "2024-08-28T11:16:42.278557Z",
          "iopub.status.idle": "2024-08-28T11:16:42.288913Z",
          "shell.execute_reply.started": "2024-08-28T11:16:42.278518Z",
          "shell.execute_reply": "2024-08-28T11:16:42.287872Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "0HAubkOh_ulD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.3) Show Images"
      ],
      "metadata": {
        "id": "4jgUuYHi_ulD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transformation to be applied to the test images\n",
        "_, test_transform = img_transform()\n",
        "\n",
        "#Note: You must train the model before using this param\n",
        "model_pth = \"/kaggle/working/trained_model/last.h5\"\n",
        "num_classes=  1\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "#Show images\n",
        "pred_show_image_grid(model_pth, device, test_transform, num_classes, num_imgs= 10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T11:16:43.937599Z",
          "iopub.execute_input": "2024-08-28T11:16:43.937998Z",
          "iopub.status.idle": "2024-08-28T11:16:50.35647Z",
          "shell.execute_reply.started": "2024-08-28T11:16:43.937961Z",
          "shell.execute_reply": "2024-08-28T11:16:50.355715Z"
        },
        "trusted": true,
        "id": "aJHTmiJK_ulD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}